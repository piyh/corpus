{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b96f57-6de8-42ad-b2e2-3fac25001bb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# THE GREAT FILE DE-DUPLICATOR\n",
    "### A solution to my fractured backups\n",
    "A program of 1000 lines begins with dependency imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3dd947-fe45-4994-b5a2-da49210349c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from multiprocess import Pool, cpu_count\n",
    "from pprint import pprint, pformat\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output, display, HTML\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "#from functools import partial\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97978f-baa3-4efe-9cd3-9021e6a3e295",
   "metadata": {},
   "source": [
    "### Enter your parameters\n",
    "Enter where you want to output your analysis files, what directories you want to analyze for duplicates and which folder names you wish to exclude from the analysis.\n",
    "Mind the backslashes playing nice with python on windows.\n",
    "\n",
    "**THE ORDER THE deDupeDirs ARE IN ARE THE PREFERRED ORDER FOR RETENTION IF DRY RUN IS DISABLED! MAKE SURE YOU ARE OK WITH LATER ENTRIES IN THE LIST HAVING DUPLICATE FILES DISABLED!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e952a8d5-8bd0-48aa-9ffd-f59bb1353e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:\\\\Users\\\\Ryan\\\\Desktop', 'D:\\\\Users\\\\Ryan', 'G:', 'F:')\n"
     ]
    }
   ],
   "source": [
    "dedupeDirs = (r'C:\\Users\\Ryan\\Desktop',\n",
    "               r'D:\\Users\\Ryan',\n",
    "               'G:',\n",
    "               'F:',\n",
    "               #'H:\\\\',\n",
    "               )\n",
    "excludeDirs = {'$RECYCLE.BIN',\n",
    "               'gdpr data',\n",
    "               'steamapps',\n",
    "               'Google Dump',\n",
    "               'Windows',\n",
    "              }\n",
    "\n",
    "excludeExtensions = {'.example',    \n",
    "}\n",
    "\n",
    "outputDir = Path(r'C:\\Users\\Ryan\\Desktop')\n",
    "\n",
    "#Assign file retention priority to dedupeDirs based on order\n",
    "#Early entries in the list will keep their files over later entries with duplicate files\n",
    "print(dedupeDirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e79f80-50d1-4bc7-894d-655c624f0447",
   "metadata": {},
   "source": [
    "# Index all files in directories\n",
    "### For a directories listed in \"deDupeDirs\", get the filenames, last modified dates, and file size. \n",
    "End result is a dataframe with all files listed within those dirs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13bc56-1953-42a3-b3aa-3aa2c2a9d7f5",
   "metadata": {},
   "source": [
    "Start off with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658c21d6-1711-4f63-b196-f7084dd4c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@dataclass\n",
    "#class FileAttr():\n",
    "#    name: str\n",
    "#    path: Path\n",
    "#    size: int\n",
    "#    mtime: int\n",
    "    \n",
    "def fileIndexer(workDir, excludeDirs, excludeExtensions): #args #*args\n",
    "    #args, not *args to work with pool\n",
    "    #workDir, excludeDirs, excludeExtensions = args[0], args[1], args[2]\n",
    "    #trying this partial approach when calling pool to simulate starmap, but still use imap\n",
    "    try:\n",
    "        from FileAttr import FileAttr\n",
    "        from pathlib import Path\n",
    "        print(f'fileIndexer start for {workDir}')\n",
    "        if not isinstance(workDir, Path):\n",
    "            workDir = Path(workDir)\n",
    "        fileAttrs = []\n",
    "        errors    = []\n",
    "        for file in workDir.glob('**/*'):\n",
    "            try:\n",
    "                if (   file.is_file() \n",
    "                        and not excludeDirs.intersection(set(file.parts)) \n",
    "                        and not excludeExtensions.intersection(set(file.suffixes))\n",
    "                   ):\n",
    "                    fa = FileAttr(file.name, file,file.stat().st_size, file.stat().st_mtime)#, set(file.parts))\n",
    "                    fileAttrs.append(fa)\n",
    "            except Exception as e:\n",
    "                    errors.append([file, e])\n",
    "        print(f'fileIndexer end for {workDir}')\n",
    "        return fileAttrs, errors\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "def myIterator():\n",
    "    for dedupeDir in dedupeDirs:\n",
    "        yield  dedupeDir, excludeDirs, excludeExtensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7baea27-dd4e-46d2-ad74-aba29b9db251",
   "metadata": {},
   "source": [
    "Index the files with multiprocessing and load to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f481517-ac55-4920-ba64-c9ec74888481",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fileAttrs  = []\n",
    "errors     = []\n",
    "#if I needed to use imap here, look at functools.partial to replace the myIterator\n",
    "with Pool(processes = int(cpu_count()/2)) as p:\n",
    "    for fileAttribute, error in p.starmap(func = fileIndexer, iterable = myIterator()):\n",
    "        fileAttrs+= fileAttribute\n",
    "        errors += error\n",
    "        \n",
    "df = pd.DataFrame(fileAttrs)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e3d85-44b9-46be-9899-c6d5619f8bd9",
   "metadata": {},
   "source": [
    "### Save your progress\n",
    "The above steps could take a while depending on how much you've hoarded, pickle the output to noodle with at a later date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed87fd8-098b-47f3-90d3-2c6122b02535",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_pickle(r'C:\\Users\\Ryan\\Desktop\\filelist.pkl')\n",
    "df.to_csv('filelist.csv', index = False)\n",
    "print('pickled and csved df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ef5e7-b5a4-4932-b8cf-17c4d9f3f553",
   "metadata": {},
   "source": [
    "### Reload your progress\n",
    "Reload if you saved to a JSON file.  You'll need to run imports and the parameter code blocks before this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b393ad2-617a-4d08-96af-521165b582de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_pickle(r'C:\\Users\\Ryan\\Desktop\\filelist.pkl')                       \n",
    "print('loaded from file')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101f707-aab6-4a2d-b87b-be742113dfa5",
   "metadata": {},
   "source": [
    "### Calculate CRC for files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e154ab5-5672-4ec6-b434-edb872a2b390",
   "metadata": {},
   "source": [
    " Define functions used in duplicate processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41860f9d-2e72-4c5a-ba70-e3e3138bf25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpCrc32(fileName):\n",
    "    #have to import within function because of multiprocessing\n",
    "    from zlib import crc32\n",
    "    try:\n",
    "        with open(fileName, 'rb') as fh:\n",
    "            hash = 0\n",
    "            while True:\n",
    "                s = fh.read(65536)\n",
    "                if not s:\n",
    "                    break\n",
    "                hash = crc32(s, hash)\n",
    "            return \"%08X\" % (hash & 0xFFFFFFFF)\n",
    "    except Exception as e:\n",
    "        x = f'{e}, {fileName}'\n",
    "        return x       \n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de47fa9-f109-48ca-af0c-9658b49e1f98",
   "metadata": {},
   "source": [
    "Calculate CRCs, takes a long time with the high disk IO to read every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d1a16-dc51-47ee-8527-5ac63909fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#shuffle your dataframe to pull randomly and so we don't linearly iterate over folders and end up doing one drive at at time\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "crcList = []\n",
    "with Pool(processes = int(cpu_count()/2), maxtasksperchild = 500) as p:\n",
    "    for cnt, crc in enumerate(p.imap(func = mpCrc32, iterable = df['path'], chunksize = 5000)):\n",
    "        crcList.append(crc)\n",
    "        sys.stderr.write(f'\\r{cnt/len(df):.0%}')\n",
    "df['crc'] = crcList\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062fa6ca-61b2-496f-a29d-4f8067663b59",
   "metadata": {},
   "source": [
    "## Checkpoint your progress  after calculating CRCs\n",
    "It takes a while to get this far since it's basically a full disk read, save your progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8656a90-36fd-483a-b2ae-c8b9b7530b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_pickle(r'C:\\Users\\Ryan\\Desktop\\filelistCRC.pkl')\n",
    "df.to_csv('filelistCRC.csv', index = False)\n",
    "print('pickled CRC populated dataframe and csved df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b764d-0385-4faa-8080-3e26d7e95707",
   "metadata": {},
   "source": [
    "### Reload progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "68f8805a-4e8a-4864-9e8a-e6617984a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from file\n",
      "len(df)=252607\n",
      "Wall time: 4.98 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>size</th>\n",
       "      <th>mtime</th>\n",
       "      <th>crc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201024</th>\n",
       "      <td>math_ops.cpython-37.pyc</td>\n",
       "      <td>D:\\Users\\Ryan\\Desktop\\dfl-venv\\Lib\\site-packag...</td>\n",
       "      <td>602</td>\n",
       "      <td>1.582502e+09</td>\n",
       "      <td>E1757630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167726</th>\n",
       "      <td>__init__.py</td>\n",
       "      <td>D:\\Users\\Ryan\\AppData\\Local\\Programs\\Python\\Py...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.586105e+09</td>\n",
       "      <td>00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91944</th>\n",
       "      <td>EC7F06D0C44964357DF15001B64BF99DABFFFAFB</td>\n",
       "      <td>D:\\Users\\Ryan\\AppData\\Local\\Mozilla\\Firefox\\Pr...</td>\n",
       "      <td>17738</td>\n",
       "      <td>1.599964e+09</td>\n",
       "      <td>FC1DE324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199764</th>\n",
       "      <td>gen_training_ops.py</td>\n",
       "      <td>D:\\Users\\Ryan\\Desktop\\dfl-venv\\Lib\\site-packag...</td>\n",
       "      <td>24963</td>\n",
       "      <td>1.582502e+09</td>\n",
       "      <td>71AED58E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104955</th>\n",
       "      <td>19da4d234f8ab01975d9d770564b826b_6085d8ec-973b...</td>\n",
       "      <td>D:\\Users\\Ryan\\AppData\\Local\\Packages\\Microsoft...</td>\n",
       "      <td>1481</td>\n",
       "      <td>1.569720e+09</td>\n",
       "      <td>0F071BB9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183846</th>\n",
       "      <td>readme.md</td>\n",
       "      <td>D:\\Users\\Ryan\\AppData\\Roaming\\discord\\0.0.308\\...</td>\n",
       "      <td>580</td>\n",
       "      <td>1.607130e+09</td>\n",
       "      <td>BDBDFA21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69087</th>\n",
       "      <td>messages.json</td>\n",
       "      <td>D:\\Users\\Ryan\\AppData\\Local\\Google\\Chrome\\User...</td>\n",
       "      <td>179</td>\n",
       "      <td>1.539055e+09</td>\n",
       "      <td>6B6C874F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242527</th>\n",
       "      <td>Paragraph I.doc</td>\n",
       "      <td>F:Files\\Old\\Iowa State\\Pre Spring 2012\\High Sk...</td>\n",
       "      <td>20480</td>\n",
       "      <td>1.178289e+09</td>\n",
       "      <td>073FBC7F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9446</th>\n",
       "      <td>31bc330521af537b7302aeadabd3d5d044ec7f</td>\n",
       "      <td>C:\\Users\\Ryan\\Desktop\\Files\\corpus\\.git\\object...</td>\n",
       "      <td>213</td>\n",
       "      <td>1.618119e+09</td>\n",
       "      <td>653D3D10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139806</th>\n",
       "      <td>application-certificate.png</td>\n",
       "      <td>D:\\Users\\Ryan\\AppData\\Local\\Packages\\TheDebian...</td>\n",
       "      <td>713</td>\n",
       "      <td>1.583113e+09</td>\n",
       "      <td>465CA9D2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "201024                            math_ops.cpython-37.pyc   \n",
       "167726                                        __init__.py   \n",
       "91944            EC7F06D0C44964357DF15001B64BF99DABFFFAFB   \n",
       "199764                                gen_training_ops.py   \n",
       "104955  19da4d234f8ab01975d9d770564b826b_6085d8ec-973b...   \n",
       "...                                                   ...   \n",
       "183846                                          readme.md   \n",
       "69087                                       messages.json   \n",
       "242527                                    Paragraph I.doc   \n",
       "9446               31bc330521af537b7302aeadabd3d5d044ec7f   \n",
       "139806                        application-certificate.png   \n",
       "\n",
       "                                                     path   size  \\\n",
       "201024  D:\\Users\\Ryan\\Desktop\\dfl-venv\\Lib\\site-packag...    602   \n",
       "167726  D:\\Users\\Ryan\\AppData\\Local\\Programs\\Python\\Py...      0   \n",
       "91944   D:\\Users\\Ryan\\AppData\\Local\\Mozilla\\Firefox\\Pr...  17738   \n",
       "199764  D:\\Users\\Ryan\\Desktop\\dfl-venv\\Lib\\site-packag...  24963   \n",
       "104955  D:\\Users\\Ryan\\AppData\\Local\\Packages\\Microsoft...   1481   \n",
       "...                                                   ...    ...   \n",
       "183846  D:\\Users\\Ryan\\AppData\\Roaming\\discord\\0.0.308\\...    580   \n",
       "69087   D:\\Users\\Ryan\\AppData\\Local\\Google\\Chrome\\User...    179   \n",
       "242527  F:Files\\Old\\Iowa State\\Pre Spring 2012\\High Sk...  20480   \n",
       "9446    C:\\Users\\Ryan\\Desktop\\Files\\corpus\\.git\\object...    213   \n",
       "139806  D:\\Users\\Ryan\\AppData\\Local\\Packages\\TheDebian...    713   \n",
       "\n",
       "               mtime       crc  \n",
       "201024  1.582502e+09  E1757630  \n",
       "167726  1.586105e+09  00000000  \n",
       "91944   1.599964e+09  FC1DE324  \n",
       "199764  1.582502e+09  71AED58E  \n",
       "104955  1.569720e+09  0F071BB9  \n",
       "...              ...       ...  \n",
       "183846  1.607130e+09  BDBDFA21  \n",
       "69087   1.539055e+09  6B6C874F  \n",
       "242527  1.178289e+09  073FBC7F  \n",
       "9446    1.618119e+09  653D3D10  \n",
       "139806  1.583113e+09  465CA9D2  \n",
       "\n",
       "[252607 rows x 5 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle(r'C:\\Users\\Ryan\\Desktop\\filelistCRC.pkl')                       \n",
    "print('loaded from file')\n",
    "print(f'{len(df)=}')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661be6a1-2417-41cd-a723-3636cd50842b",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c3cde-ec6e-46d4-a665-a26fac4c8d6f",
   "metadata": {},
   "source": [
    "### Filter dataframe down to duplicate CRCs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a39fda4d-02a4-43ce-9dc9-59e687962d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 399 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>size</th>\n",
       "      <th>mtime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F05129F1</th>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57F5D79F</th>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622E720</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14A285AC</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518E617C</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13F89049</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F021BB50</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882CD33</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EF3D72E4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14105E5E</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37118 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  path  size  mtime\n",
       "crc                              \n",
       "F05129F1  1143  1143  1143   1143\n",
       "57F5D79F   156   156   156    156\n",
       "2622E720   133   133   133    133\n",
       "14A285AC   128   128   128    128\n",
       "518E617C   126   126   126    126\n",
       "...        ...   ...   ...    ...\n",
       "13F89049     2     2     2      2\n",
       "F021BB50     2     2     2      2\n",
       "1882CD33     2     2     2      2\n",
       "EF3D72E4     2     2     2      2\n",
       "14105E5E     2     2     2      2\n",
       "\n",
       "[37118 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = df[df['crc']!='00000000']\n",
    "grouped = df.groupby('crc')\n",
    "#grouped.filter('')\n",
    "grouped = grouped.count().sort_values('path', ascending = False)\n",
    "grouped = grouped[grouped['path']>1]\n",
    "duplicatedCRCs = set(grouped.index)\n",
    "df = df[df['crc'].isin(duplicatedCRCs) ]\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a286a4d-bd4e-4966-b64d-f2aaabc5217d",
   "metadata": {},
   "source": [
    "### Use this to explore and add more exclusions\n",
    "If a directory comes up with 12,000 files in it and it's some Chrome cache file, you can probably ignore add it to your excludeDirs list.\n",
    "Same idea for file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8832605f-4917-47ec-8848-82e35ecac20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before len(df)=39793\n",
      "after len(df)=39537\n"
     ]
    }
   ],
   "source": [
    "#Directory Exclusions\n",
    "additionalExclusions =  {\n",
    "    'Microsoft.XboxGamingOverlay_8wekyb3d8bbwe',\n",
    "    'Dolphin',\n",
    "    'cache',\n",
    "    'Cache',\n",
    "    'cache2',\n",
    "    'Code Cache',\n",
    "    'Vita',\n",
    "    'TheDebianProject.DebianGNULinux_76v4gfsz19hv4',\n",
    "    'RCTCache',\n",
    "    'NVIDIA',\n",
    "    '__pycache__',\n",
    "    'site-packages',\n",
    "    'TurboTax',    \n",
    "    'Xbox',\n",
    "    'CacheStorage',\n",
    "    'CachedData',\n",
    "    'CINEBENCH R15.038_RC184115',\n",
    "    'solr',\n",
    "    'dfl-venv',\n",
    "    'MovieMaker',\n",
    "}\n",
    "excludeDirs.update(additionalExclusions)\n",
    "print(f'before {len(df)=}')\n",
    "df = df[[not excludeDirs.intersection(set(x.parts)) for x in df['path']]]\n",
    "print(f'after {len(df)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f17d1c61-da88-4436-9cc9-cd68e14e5644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 898 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>size</th>\n",
       "      <th>mtime</th>\n",
       "      <th>crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\photos\\Old Photos\\Dump</th>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F:Files\\photos\\Old Photos\\Dump</th>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G:photos\\Old Photos\\Dump</th>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G:projects\\processing-3.0.1\\modes\\java\\reference</th>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\reference</th>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F:Files\\code\\processing-3.0.1\\modes\\java\\reference</th>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G:code\\processing-3.0.1\\modes\\java\\reference</th>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\Rpi\\camera</th>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G:photos\\Old Photos\\recovered pictures</th>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F:Files\\photos\\Old Photos\\recovered pictures</th>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  path  size  mtime  \\\n",
       "parent                                                                        \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\photos\\Old Photos\\Dump  1002  1002  1002   1002   \n",
       "F:Files\\photos\\Old Photos\\Dump                      1002  1002  1002   1002   \n",
       "G:photos\\Old Photos\\Dump                            1002  1002  1002   1002   \n",
       "G:projects\\processing-3.0.1\\modes\\java\\reference     639   639   639    639   \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...   639   639   639    639   \n",
       "F:Files\\code\\processing-3.0.1\\modes\\java\\reference   639   639   639    639   \n",
       "G:code\\processing-3.0.1\\modes\\java\\reference         639   639   639    639   \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\Rpi\\camera          591   591   591    591   \n",
       "G:photos\\Old Photos\\recovered pictures               356   356   356    356   \n",
       "F:Files\\photos\\Old Photos\\recovered pictures         356   356   356    356   \n",
       "\n",
       "                                                     crc  \n",
       "parent                                                    \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\photos\\Old Photos\\Dump  1002  \n",
       "F:Files\\photos\\Old Photos\\Dump                      1002  \n",
       "G:photos\\Old Photos\\Dump                            1002  \n",
       "G:projects\\processing-3.0.1\\modes\\java\\reference     639  \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...   639  \n",
       "F:Files\\code\\processing-3.0.1\\modes\\java\\reference   639  \n",
       "G:code\\processing-3.0.1\\modes\\java\\reference         639  \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\Rpi\\camera          591  \n",
       "G:photos\\Old Photos\\recovered pictures               356  \n",
       "F:Files\\photos\\Old Photos\\recovered pictures         356  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#let's try to find the most common folders files are in\n",
    "df['parent'] = [x.parent for x in df['path']]\n",
    "grouped = df.groupby('parent')\n",
    "grouped.count().sort_values('name', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3abd57a3-e602-4e0a-abbd-1eddce1aa7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before len(df)=51568\n",
      "after len(df)=39793\n"
     ]
    }
   ],
   "source": [
    "#File Extension Exclusions\n",
    "additionalExclusions =  {\n",
    "    '.pyi',\n",
    "    '.pde',\n",
    "    '.html',\n",
    "    None,\n",
    "    '.xml',\n",
    "    '.dll',\n",
    "    '',\n",
    "}\n",
    "excludeExtensions.update(additionalExclusions)\n",
    "print(f'before {len(df)=}')\n",
    "df = df[[not excludeExtensions.intersection(set(x.suffixes)) for x in df['path']]]\n",
    "print(f'after {len(df)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2c798a60-417e-4e4c-ad37-3e16b263d39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>size</th>\n",
       "      <th>mtime</th>\n",
       "      <th>crc</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.jpg</th>\n",
       "      <td>9448</td>\n",
       "      <td>9448</td>\n",
       "      <td>9448</td>\n",
       "      <td>9448</td>\n",
       "      <td>9448</td>\n",
       "      <td>9448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.png</th>\n",
       "      <td>3702</td>\n",
       "      <td>3702</td>\n",
       "      <td>3702</td>\n",
       "      <td>3702</td>\n",
       "      <td>3702</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>3556</td>\n",
       "      <td>3556</td>\n",
       "      <td>3556</td>\n",
       "      <td>3556</td>\n",
       "      <td>3556</td>\n",
       "      <td>3556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.mkv</th>\n",
       "      <td>2801</td>\n",
       "      <td>2801</td>\n",
       "      <td>2801</td>\n",
       "      <td>2801</td>\n",
       "      <td>2801</td>\n",
       "      <td>2801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.py</th>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.class</th>\n",
       "      <td>1476</td>\n",
       "      <td>1476</td>\n",
       "      <td>1476</td>\n",
       "      <td>1476</td>\n",
       "      <td>1476</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.mp3</th>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.frm</th>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.java</th>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.epub</th>\n",
       "      <td>756</td>\n",
       "      <td>756</td>\n",
       "      <td>756</td>\n",
       "      <td>756</td>\n",
       "      <td>756</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  path  size  mtime   crc  parent\n",
       "suffix                                       \n",
       ".jpg    9448  9448  9448   9448  9448    9448\n",
       ".png    3702  3702  3702   3702  3702    3702\n",
       "        3556  3556  3556   3556  3556    3556\n",
       ".mkv    2801  2801  2801   2801  2801    2801\n",
       ".py     1631  1631  1631   1631  1631    1631\n",
       ".class  1476  1476  1476   1476  1476    1476\n",
       ".mp3    1299  1299  1299   1299  1299    1299\n",
       ".frm    1028  1028  1028   1028  1028    1028\n",
       ".java    794   794   794    794   794     794\n",
       ".epub    756   756   756    756   756     756"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try to find the most common folders stuff is in\n",
    "#df = \n",
    "df.loc[:,('suffix')] = [x.suffix for x in df['path']]\n",
    "grouped = df.groupby('suffix')\n",
    "grouped.count().sort_values('path', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e5d196da-7674-4820-82d4-88286408b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates in folder C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\bin\\antlr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_name</th>\n",
       "      <th>duplicate_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\bin\\antlr\\ExtendedCommonASTWithHiddenTokens.class</th>\n",
       "      <td>ExtendedCommonASTWithHiddenTokens.class</td>\n",
       "      <td>F:Files\\code\\processing-3.0.1\\modes\\java\\bin\\a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\bin\\antlr\\ExtendedCommonASTWithHiddenTokens.class</th>\n",
       "      <td>ExtendedCommonASTWithHiddenTokens.class</td>\n",
       "      <td>G:code\\processing-3.0.1\\modes\\java\\bin\\antlr\\E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\bin\\antlr\\ExtendedCommonASTWithHiddenTokens.class</th>\n",
       "      <td>ExtendedCommonASTWithHiddenTokens.class</td>\n",
       "      <td>G:projects\\processing-3.0.1\\modes\\java\\bin\\ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\bin\\antlr\\TokenStreamCopyingHiddenTokenFilter.class</th>\n",
       "      <td>TokenStreamCopyingHiddenTokenFilter.class</td>\n",
       "      <td>G:code\\processing-3.0.1\\modes\\java\\bin\\antlr\\T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\bin\\antlr\\TokenStreamCopyingHiddenTokenFilter.class</th>\n",
       "      <td>TokenStreamCopyingHiddenTokenFilter.class</td>\n",
       "      <td>G:projects\\processing-3.0.1\\modes\\java\\bin\\ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0.1\\modes\\java\\bin\\antlr\\TokenStreamCopyingHiddenTokenFilter.class</th>\n",
       "      <td>TokenStreamCopyingHiddenTokenFilter.class</td>\n",
       "      <td>F:Files\\code\\processing-3.0.1\\modes\\java\\bin\\a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 primary_name  \\\n",
       "primary_path                                                                                    \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...    ExtendedCommonASTWithHiddenTokens.class   \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...    ExtendedCommonASTWithHiddenTokens.class   \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...    ExtendedCommonASTWithHiddenTokens.class   \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  TokenStreamCopyingHiddenTokenFilter.class   \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  TokenStreamCopyingHiddenTokenFilter.class   \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  TokenStreamCopyingHiddenTokenFilter.class   \n",
       "\n",
       "                                                                                       duplicate_file  \n",
       "primary_path                                                                                           \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  F:Files\\code\\processing-3.0.1\\modes\\java\\bin\\a...  \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  G:code\\processing-3.0.1\\modes\\java\\bin\\antlr\\E...  \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  G:projects\\processing-3.0.1\\modes\\java\\bin\\ant...  \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  G:code\\processing-3.0.1\\modes\\java\\bin\\antlr\\T...  \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  G:projects\\processing-3.0.1\\modes\\java\\bin\\ant...  \n",
       "C:\\Users\\Ryan\\Desktop\\Files\\code\\processing-3.0...  F:Files\\code\\processing-3.0.1\\modes\\java\\bin\\a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#build a django/flask front end\n",
    "#have an html dataframe table with selection checkboxes\n",
    "    #have the ability to select all, or just buttons to skip, ignore, remove from future compares, or delete non c drive dupes\n",
    "        #buttons to exclude part of a given folder, a file extension\n",
    "    #have the ability to move all contents from a folder with deletions into the c drive equivalent folder\n",
    "        #this can only happen after duplication on the c drive is resolved\n",
    "    #deleter moves to a recycle bin that can be restored from\n",
    "\n",
    "#group by highest level parent and recursively build a tree\n",
    "    #have some kind of a winDirStat visualization\n",
    "    \n",
    "dirs = [Path(x).as_posix() for x in dedupeDirs]\n",
    "primary = dirs[0]\n",
    "secondaries = dirs[1:]\n",
    "\n",
    "try:\n",
    "    del df['size']\n",
    "    del df['mtime']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "cDrive    = df[[x.as_posix().startswith(posixDedupeDirs[0]) for x in df['path']]]\n",
    "nonCDrive = df[[not x.as_posix().startswith(posixDedupeDirs[0]) for x in df['path']]]\n",
    "\n",
    "merged = cDrive.merge(nonCDrive, on = ['crc'], suffixes = ('_c', '_dupe'))#, indicator = True)\n",
    "\n",
    "mergedFolderGrouping = merged.groupby('parent_c')\n",
    "\n",
    "mergedFolderGrouping = list(mergedFolderGrouping)\n",
    "shuffle(mergedFolderGrouping)\n",
    "\n",
    "for parent, group in mergedFolderGrouping:\n",
    "    print(f'duplicates in folder {parent}')\n",
    "    del group['parent_dupe']\n",
    "    del group['name_dupe']\n",
    "    del group['crc']\n",
    "    del group['parent_c']\n",
    "    del group['suffix_c']\n",
    "    del group['suffix_dupe']\n",
    "    group.rename(columns = {'name_c':'primary_name', 'path_c':'primary_path', 'path_dupe':'duplicate_file'}, inplace = True)\n",
    "    group.set_index('primary_path', inplace = True)\n",
    "    display(group)\n",
    "    break\n",
    "    clear_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740d84a-4766-4ee6-8056-13c4cb112ce4",
   "metadata": {},
   "source": [
    "### Prioritize\n",
    "  - Assign a root tier to each file\n",
    "  - Assign a priority based on path length to resolve disputes within root tier### Assign a priority based on path length to resolve disputes within root tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93cb32c-83a0-406a-8d2b-32d6aada3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def getTier(file):\n",
    "    file = file.as_posix()\n",
    "    return int([rootTier for rootTier, posix_path in dedupeTiers if file.startswith(posix_path)][0])\n",
    "\n",
    "dedupeTiers = [(rootTier,Path(directory).as_posix()) for rootTier,directory in enumerate(dedupeDirs)]\n",
    "df['rootTier'] = df['path'].apply(getTier)\n",
    "\n",
    "#prioritize shortest len paths\n",
    "df['pathLen'] = df['path'].map(Path.as_posix).str.len()\n",
    "df.sort_values(by= ['crc','name','rootTier', 'pathLen'], inplace = True)\n",
    "df['priority'] = [cnt for cnt, x in enumerate(df.index)]\n",
    "del df['pathLen']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc15addf-c14a-4dea-833a-5f1a1ba94482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isascii',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'removeprefix',\n",
       " 'removesuffix',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Path('C:/Users/Ryan/Desktop/')\n",
    "dir('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0936e1a-b92e-45f4-8939-f79495acfcb0",
   "metadata": {},
   "source": [
    "# HERE BE DRAGONS\n",
    "\n",
    "### TODO:\n",
    "I can't go duplicate by duplicate. There's too much and I risk breaking files by deleting common needed components.  I need to know if an entire subdir is an exact match, and match high up the trees.  Basically match on folder name, folder contents, number of stuff in folder\n",
    " - maybe do something like find a folder with name Mom Pictures\n",
    "   - identify exact folder name matches\n",
    "   - fina all matches\n",
    "   - crc different folder instances with all subdirs\n",
    "   - copy from all other drives to primary if crc does not exist\n",
    "       - later add step to  delete duplicated non primary copies\n",
    "   - do a folder by folder approach\n",
    "\n",
    "\n",
    "### Only run on exact duplicates first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5a1fe2b-7592-43ab-9296-9964c387627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the index and crc one pool process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96c284-3916-4808-9ec7-57f0784c6e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = list(df.groupby('parent'))#.sort_values(len(path.parts))\n",
    "display(grouped[0][1])\n",
    "\n",
    "#for group in grouped, start deleting stuff\n",
    "#for _, dupeGroup in grouped:\n",
    "#    dupeGroup.sort_values('rootTier', inplace = True)\n",
    "#    display(dupeGroup)\n",
    "#    input()\n",
    "#    clear_output()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(type(dupeGroup))\n",
    "#    print(dupeGroup)\n",
    "    #dupeGroup = \n",
    "    #print(type(dupeGroup))\n",
    "    #print([x for x in dupeGroup])\n",
    "    #clear_output()\n",
    "    #display(HTML(dupeGroup.to_html()))\n",
    "    \n",
    "#    input('press enter to continue')\n",
    "\n",
    "    #print(dupeGroup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8d8a0-bffb-4544-ab52-d6d22f20b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows how many duplicate groups (\"path_Count\") we have by number of duplicate files\n",
    "print(len(grouped))\n",
    "dupeGroupSizeCount = grouped.copy().add_suffix('_Count').reset_index()\n",
    "dupeGroupSizeCount = dupeGroupSizeCount.groupby('name_Count').count()[['path_Count']]\n",
    "dupeGroupSizeCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ce2e9-426c-42a6-adf8-4b4b5582f8df",
   "metadata": {},
   "source": [
    "### let's do some analysis by file suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe374d3-1bd5-4762-8773-dd183eb4d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixesCounter = Counter()\n",
    "\n",
    "for k,dupeList in dupeDict.items(): \n",
    "    for file in dupeList:\n",
    "        #for suffix in file['pathObj'].suffixes:\n",
    "        suffixesCounter[file['pathObj'].suffix] += 1\n",
    "suffixesCounter = [(k,v) for k,v in suffixesCounter.items()]\n",
    "suffixesCounter.sort(key = lambda k: k[1], reverse=True)\n",
    "\n",
    "#top 20 duplicated \n",
    "pprint(suffixesCounter[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bbff30-ad4d-4402-898e-4db707af568a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### start by figuring out duplication categories\n",
    " - same name, same size, same mtime, same hash different dedupeDirs\n",
    "     - can safely delete one of them based on priority\n",
    " - same name, same size, different mtime\n",
    "     - hash and branch logic if different\n",
    " - same name, different size \n",
    "     - send to manual review queue, potentially prefer the newer one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a37a0f-ca39-4228-ab87-2e865cd8f0e1",
   "metadata": {},
   "source": [
    "For my deletion logic I need the dry run I need to output a file that would say here's the original path and here's the moved to path which is basically the recycle bin and then I need to be able to restore files to and from that recycle bin before permanent deletion\n",
    "\n",
    "Make sure this code to restore stuff from the recycle bin as well tested so that I don't break any processes I can't remember\n",
    "\n",
    "All unique files on my non-primary drive need to be pulled over and brought into the formal file structure\n",
    "\n",
    "Look into whatever line is tech tips use that was basically the r seeing log rotate thing where I can automate my backups I need to have snapshots as well as like I don't schedule to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b6aca-68e9-48cd-b377-c3de5fe94bb9",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "group by a combination of name, size, crc.\n",
    "if the crc checks match, analyze \n",
    "group by analysis has an order by clause, keep the top x and have a function for delete with dry run as the base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1afc1-c159-407a-9df9-dd68a9787ad9",
   "metadata": {},
   "source": [
    "### Let's get deleting files\n",
    "Work out the priority of each file to conslidate everything on one disk first.\n",
    "\n",
    "Dry run is enabled unless you disable it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e416d8-c2b3-4cd1-a6a5-9e5a68a51c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return f\"{num:3.1f}{unit}{suffix}\" \n",
    "        num /= 1024.0\n",
    "    return \"{num:.1f}Yi{suffix}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850d7c8-fc98-405a-81e2-fdaed8824d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Assuming that dataframes df1 and df2 are already defined:\n",
    "\n",
    "#display(df)\n",
    "display(df.to_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd04f41-3251-475e-b016-0a814eaedfda",
   "metadata": {},
   "source": [
    "dryRun = True\n",
    "\n",
    "## TODO:\n",
    " - compare by file attributes, basically just size and name\n",
    "     -  then by hash if same name/size\n",
    " - if name/size disagree, put in a conflict csv to review later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca46886-2137-4dfc-b23b-53cd0b829086",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%time\n",
    "#my group by root tier logic seems to be working \n",
    "grouped = df.groupby('crc', sort = False)\n",
    "\n",
    "#for cnt, (crc, group) in enumerate(grouped):\n",
    "#    if len(group) == 1 or crc == '00000000':\n",
    "#        continue\n",
    "    #if group['rootTier'].min() == group['rootTier'].max():\n",
    "    #    continue\n",
    "    #clear_output()\n",
    "    #display(group[group['rootTier'] == group['rootTier'].max()])\n",
    "    #display(group)\n",
    "    #time.sleep(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e38b1-d315-45a5-96ff-d36bd1a0975b",
   "metadata": {},
   "source": [
    "\n",
    "Bold \t**bold text**\n",
    "*italicized text*\n",
    "\n",
    "Blockquote \t> blockquote\n",
    "Ordered List \t\n",
    "1. First item\n",
    "2. Second item\n",
    "3. Third item\n",
    "Unordered List \t\n",
    "- First item\n",
    "- Second item\n",
    "- Third item\n",
    "Code \t`code`\n",
    "Horizontal Rule \t---\n",
    "Link \t\n",
    "[title](https://www.example.com)\n",
    "Image \t\n",
    "![alt text](image.jpg)\n",
    "\n",
    "### Results \n",
    "| Stretch/Untouched | ProbDistribution | Accuracy |\n",
    "| :- | -: | :-: |\n",
    "| Stretched | Gaussian | .843\n",
    "\n",
    " ```\n",
    "{\n",
    "  \"firstName\": \"John\",\n",
    "  \"lastName\": \"Smith\",\n",
    "  \"age\": 25\n",
    "}\n",
    "``` \n",
    "footnote \tHere's a sentence with a footnote. [^1]\n",
    "\n",
    "[^1]: This is the footnote.\n",
    "Heading ID \n",
    "### My Great Heading {#custom-id}\n",
    "Definition List \t\n",
    "term\n",
    ": definition\n",
    "\n",
    "Task List \t\n",
    "- [x] Write the press release\n",
    "- [ ] Update the website\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
